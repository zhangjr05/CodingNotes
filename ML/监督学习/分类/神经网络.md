# 神经网络

从零实现一个基础的神经网络，用于**二分类**任务。

## 基本原理

神经网络由多层神经元组成：

- **输入层**：接收特征数据
- **隐藏层**：进行特征变换和提取
- **输出层**：生成最终预测结果

每个神经元接收来自上一层的输入，计算加权和并应用激活函数，然后将结果传递给下一层。

## 代码实现

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_moons
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score


class NN:
    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.01):
        '''初始化神经网络参数'''
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.output_size = output_size
        self.learning_rate = learning_rate
        self.loss_history = []

        # 使用He初始化参数
        self.W1 = np.random.randn(input_size, hidden_size) * np.sqrt(2 / input_size)
        self.b1 = np.zeros((1, hidden_size))
        self.W2 = np.random.randn(hidden_size, output_size) * np.sqrt(2 / hidden_size)
        self.b2 = np.zeros((1, output_size))

    def relu(self, x):
        '''ReLU激活函数'''
        return np.maximum(0, x)
    
    def relu_derivative(self, x):
        '''ReLU导数'''
        return (x > 0).astype(float)
    
    def sigmoid(self, x):
        '''Sigmoid激活函数'''
        return 1 / (1 + np.exp(-x))
    
    def forward(self, X):
        '''前向传播'''
        # 第一层：输入 -> 隐藏层
        self.z1 = np.dot(X, self.W1) + self.b1
        self.a1 = self.relu(self.z1)

        # 第二层：隐藏层 -> 输出层
        self.z2 = np.dot(self.a1, self.W2) + self.b2
        self.a2 = self.sigmoid(self.z2)  # 二分类使用sigmoid

        return self.a2
    
    def compute_loss(self, y_true, y_pred):
        '''计算二元交叉熵损失'''
        m = y_true.shape[0]
        epsilon = 1e-15
        loss = -1 / m * np.sum(y_true * np.log(y_pred + epsilon) + (1 - y_true) * np.log(1 - y_pred + epsilon))
        return loss
    
    def backward(self, X, y):
        '''反向传播计算梯度'''
        m = X.shape[0]

        # 输出层误差
        dz2 = self.a2 - y
        dW2 = 1 / m * np.dot(self.a1.T, dz2)
        db2 = 1 / m * np.sum(dz2, axis=0, keepdims=True)

        # 隐藏层误差
        dz1 = np.dot(dz2, self.W2.T) * self.relu_derivative(self.z1)
        dW1 = 1 / m * np.dot(X.T, dz1)
        db1 = 1 / m * np.sum(dz1, axis=0, keepdims=True)

        # 更新参数
        self.W2 -= self.learning_rate * dW2
        self.b2 -= self.learning_rate * db2
        self.W1 -= self.learning_rate * dW1
        self.b1 -= self.learning_rate * db1
    
    def fit(self, X, y, epochs=1000, verbose=True):
        '''训练神经网络'''
        for epoch in range(epochs):
            # 前向传播
            y_pred = self.forward(X)

            # 计算损失
            loss = self.compute_loss(y, y_pred)
            self.loss_history.append(loss)

            # 反向传播
            self.backward(X, y)

            if verbose and epoch % 100 == 0:
                print(f"Epoch {epoch}, Loss: {loss:.4f}")
        
        return self
    
    def predict(self, X, threshold=0.5):
        '''预测类别'''
        y_pred = self.forward(X)
        return (y_pred >= threshold).astype(int)
    
    def predict_proba(self, X):
        '''预测概率'''
        return self.forward(X)
    


if __name__ == "__main__":
    # 生成月牙形数据集
    X, y = make_moons(n_samples=1000, noise=0.2)
    y = y.reshape(-1, 1)  # 调整y的形状为列向量
    
    # 数据预处理
    scaler = StandardScaler()
    X = scaler.fit_transform(X)
    
    # 划分训练集和测试集
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # 创建并训练神经网络
    model = NN(input_size=2, hidden_size=10, output_size=1)
    model.fit(X_train, y_train, epochs=2000)
    
    # 评估模型
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"测试集准确率: {accuracy:.4f}")
    
    # 绘制损失曲线
    plt.figure(figsize=(10, 4))
    plt.subplot(1, 2, 1)
    plt.plot(model.loss_history)
    plt.title('Train Loss')
    plt.xlabel('times of iterations')
    plt.ylabel('loss')
    
    # 绘制决策边界
    plt.subplot(1, 2, 2)
    
    # 创建网格点
    h = 0.02
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))
    
    # 预测网格点的类别
    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    
    # 绘制决策边界和数据点
    plt.contourf(xx, yy, Z, alpha=0.8)
    plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test.reshape(-1),
                edgecolors='k', marker='o', s=50)
    plt.title('Decision boundary')
    plt.xlabel('feature1')
    plt.ylabel('feature2')
    
    plt.tight_layout()
    plt.show()
```
