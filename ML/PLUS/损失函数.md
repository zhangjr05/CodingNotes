# 损失函数

损失函数是机器学习和深度学习中的核心组件，**用于衡量模型预测值与真实值之间的差异**。不同任务和模型架构需要不同类型的损失函数。

## 回归损失函数

1. **均方误差 (MSE)**
   - 公式: $$L_{MSE} = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2$$
   - 特点: 对异常值敏感，惩罚较大误差
   - 应用: 线性回归、神经网络回归
   - 优点: 数学性质好，易于求导
   - 缺点: 对异常值过于敏感

2. **平均绝对误差 (MAE)**
   - 公式: $$L_{MAE} = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i|$$
   - 特点: 对异常值不敏感，惩罚与误差成正比
   - 应用: 回归问题，特别是有异常值时
   - 优点: 对异常值鲁棒
   - 缺点: 在零点不可导

3. **Huber损失**
    - 公式: $$L_{\delta}(y, \hat{y}) = \begin{cases}\frac{1}{2}(y - \hat{y})^2, & \text{if } |y - \hat{y}| \leq \delta \\\delta(|y - \hat{y}| - \frac{1}{2}\delta), & \text{otherwise}\end{cases}$$
    - 特点: 结合MSE和MAE的优点
    - 应用: 鲁棒回归
    - 优点: 对异常值不敏感，处处可导
    - 缺点: 需要设置额外的δ参数

## 分类损失函数

1. **交叉熵损失 (Cross-Entropy Loss)**
    - 二元分类公式: $$L_{CE} = -\frac{1}{n}\sum_{i=1}^{n}[y_i\log(\hat{y}_i) + (1-y_i)\log(1-\hat{y}_i)]$$
    - 多分类公式: $$L_{CE} = -\frac{1}{n}\sum_{i=1}^{n}\sum_{j=1}^{m}y_{ij}\log(\hat{y}_{ij})$$
    - 特点: 惩罚错误分类，尤其是高置信度的错误
    - 应用: 逻辑回归、神经网络分类
    - 优点: 训练效果好，概率解释清晰
    - 缺点: 对噪声标签敏感

2. **铰链损失 (Hinge Loss)**
    - 公式: $$L_{hinge} = \max(0, 1 - y \cdot \hat{y})$$
    - 特点: 只关心边界附近的样本
    - 应用: 支持向量机(SVM)
    - 优点: 对噪声鲁棒，稀疏支持向量
    - 缺点: 不输出概率

3. **焦点损失 (Focal Loss)**
    - 公式: $$L_{FL} = -\alpha(1-\hat{y}_i)^\gamma y_i\log(\hat{y}_i)$$
    - 特点: 降低易分样本的权重，关注难分样本
    - 应用: 目标检测，不平衡分类
    - 优点: 解决类别不平衡问题
    - 缺点: 有额外超参数γ和α需要调整

## 特殊损失函数

1. **Dice损失**
    - 公式: $$L_{Dice} = 1 - \frac{2|X \cap Y|}{|X| + |Y|}$$
    - 特点: 直接优化IoU相关指标
    - 应用: 医学图像分割
    - 优点: 适合类别不平衡的分割问题
    - 缺点: 数学性质不如交叉熵好

2. **KL散度 (Kullback-Leibler Divergence)**
    - 公式: $$D_{KL}(P||Q) = \sum_{i} P(i) \log\frac{P(i)}{Q(i)}$$
    - 特点: 测量两个概率分布的差异
    - 应用: 变分自编码器(VAE)、知识蒸馏
    - 优点: 适合分布匹配问题
    - 缺点: 非对称性

3. **对比损失 (Contrastive Loss)**
    - 公式: $$L(y,d) = (1-y)\frac{1}{2}d^2 + y\frac{1}{2}\max(0, m-d)^2$$
    - 特点: 拉近相似样本，推开不相似样本
    - 应用: 自监督学习，度量学习
    - 优点: 学习有意义的表示
    - 缺点: 需要精心设计样本对

## 选择损失函数的指导原则

- 任务类型: 回归、分类或特殊任务
- 数据分布: 是否有异常值，类别是否平衡
- 优化目标: 最大化准确率、精确率、召回率等
- 训练稳定性: 有些损失函数可能导致训练不稳定
- 计算效率: 复杂损失函数可能增加计算负担

在实际应用中，往往需要根据具体问题特点选择或组合多种损失函数，以达到最佳效果。
